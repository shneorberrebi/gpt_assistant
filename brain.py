# brain.py â€“ ×’×¨×¡×” ××©×•×“×¨×’×ª ×¢× ×”×‘× ×ª ×”×§×©×¨ ×—×›××” ×•×©××™×¨×” ×¢×œ ×¤×¢×•×œ×•×ª

import time
import web_browser_utils
import web_reader
import web_clicker
import web_interactor

from video_editor import handle_video_editing
from smart_clicker import click_text_on_screen
from screen_capture import take_screenshot
from screen_ocr import extract_text_from_image, extract_texts_with_positions
from gpt_client import ask_gpt
from screen_context_filter import summarize_screen_for_gpt
from keyboard_typer import type_text
from window_utils import focus_browser_window
from bs4 import BeautifulSoup

from video_editing_prompt_instructions import get_video_editing_prompt

import json, os

# ğŸ’¾ ×¤×¨×˜×™× ××™×©×™×™×
personal_info = {
    "email": "lutya.co@gmail.com",
    "×©×": "shneor",
    "×˜×œ×¤×•×Ÿ": "0585333099"
}

# ğŸ§  ×–×™×›×¨×•×Ÿ ×¤×¢×•×œ×•×ª â€“ ×›×“×™ ×œ× ×œ×—×–×•×¨ ×¢×œ ××•×ª×Ÿ ×¤×¢×•×œ×•×ª
executed_actions = set()
def load_memory():
    if os.path.exists("executed_memory.json"):
        with open("executed_memory.json", "r", encoding="utf-8") as f:
            return set(json.load(f))
    return set()
def save_memory():
    with open("executed_memory.json", "w", encoding="utf-8") as f:
        json.dump(list(executed_actions), f, ensure_ascii=False, indent=2)
executed_actions = load_memory()

def normalize_action(line):
    return line.replace(" ", "").replace(":", "").lower()

# ğŸ–±ï¸ ×œ×—×™×¦×” ×—×›××” ×¢× ×”××ª× ×”
def wait_and_click(target_text, max_wait=10):
    for _ in range(max_wait):
        if click_text_on_screen(target_text):
            return True
        time.sleep(1)
    print(f"âš ï¸ ×œ× × ××¦× ×’× ××—×¨×™ {max_wait} ×©× ×™×•×ª: {target_text}")
    return False

# â³ ×”××ª× ×” ×¢×“ ×©×”×¢××•×“ ×™×˜×¢×Ÿ (×œ×¤×™ ×ª×•×›×Ÿ ×‘×¤×•×¢×œ)
def wait_until_page_has_text(min_words=30, timeout=20):
    driver = web_browser_utils.get_browser()
    for _ in range(timeout):
        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")
        texts = [el.get_text(strip=True) for el in soup.find_all(['h1','p','li','button','a']) if el.get_text(strip=True)]
        if len(" ".join(texts).split()) >= min_words:
            print("âœ… ×”×¢××•×“ × ×˜×¢×Ÿ.")
            return True
        time.sleep(1)
    print("â° ×¢×‘×¨ ×”×–××Ÿ â€“ ×œ× × ×˜×¢×Ÿ ××¡×¤×™×§ ×˜×§×¡×˜.")
    return False

# ğŸŒ ×”×©×œ××ª ×§×™×©×•×¨ ×—×›××”
def clean_url(text):
    text = text.strip().lower()
    if text.startswith("http"):
        return text
    if "." in text:
        return "https://" + text
    try:
        print(f"ğŸ§  ×©×•××œ ××ª GPT ××” ×”×§×™×©×•×¨ ×©×œ: {text}")
        response = ask_gpt(f"×”×©×œ× ×œ×™ ×§×™×©×•×¨ ×××™×ª×™ ×œ××ª×¨ ×”×‘× ×¨×§ ×‘×¦×•×¨×” ×©×œ ×›×ª×•×‘×ª URL ×‘×œ×‘×“ ×‘×œ×™ ×˜×§×¡×˜ × ×•×¡×£: {text}")
        url = response.strip().split()[0]
        if url.startswith("http"):
            return url
    except Exception as e:
        print(f"âš ï¸ ×©×’×™××” ×‘×”×©×œ××ª ×§×™×©×•×¨: {e}")
    return ""
# ğŸš€ ×”×¤×¢×œ×ª GPT ×¢×œ ×ª×•×›× ×™×ª ×¤×¢×•×œ×”
def execute_plan(plan_text):
    if not plan_text.strip():
        print("âš ï¸ ××™×Ÿ ×ª×•×›× ×™×ª.")
        return
    lines = plan_text.strip().splitlines()
    for line in lines:
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        normalized = normalize_action(line)
        if normalized in executed_actions:
            print(f"â© ××“×œ×’ â€“ ×›×‘×¨ ×‘×•×¦×¢: {line}")
            continue
        executed_actions.add(normalized)
        print(f"â¡ï¸ ××‘×¦×¢: {line}")
        try:
            if "×¤×ª×— ××ª×¨" in line:
                url = line.split("×¤×ª×— ××ª×¨")[-1].strip()
                full_url = clean_url(url)
                if full_url:
                    web_browser_utils.open_website(full_url)
                    wait_until_page_has_text()
                    focus_browser_window()

            elif any(k in line for k in ["×ª×™×›× ×¡ ×œ", "×ª×ª×—×™×œ ×‘", "×ª×¤×ª×— ××ª"]):
                parts = line.split()
                url = parts[-1].strip() if len(parts) > 1 else ""
                if not url:
                    print(f"âš ï¸ ×œ× × ××¦××” ×›×ª×•×‘×ª ×‘×ª×•×š: {line}")
                    continue
                full_url = clean_url(url)
                if full_url:
                    web_browser_utils.open_website(full_url)
                    wait_until_page_has_text()
                    focus_browser_window()

            elif "×œ×—×¥ ×¢×œ" in line:
                wait_and_click(line.split("×œ×—×¥ ×¢×œ")[-1].strip())

            elif "×¦×œ× ××¡×š" in line:
                take_screenshot()

            elif "×§×¨× ××”××¡×š" in line:
                img = take_screenshot()
                extract_text_from_image(img)

            elif "×¢×¨×•×š ×¡×¨×˜×•×Ÿ" in line:
                handle_video_editing(line)

            elif "×”×§×œ×“ ××ª" in line:
                val = line.split("×”×§×œ×“ ××ª")[-1].strip()
                type_text(personal_info.get(val, val))
                time.sleep(1)

        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×‘×™×¦×•×¢: {line} -> {e}")
    save_memory()

# ğŸ’¬ ×¤×§×•×“×” ×¨×’×™×œ×” ××”×¦'××˜ ×”×¨××©×™
def process_command(command):
    print(f"ğŸ§  ××‘×¦×¢ ×¤×§×•×“×” ××”×¦'××˜: {command}")
    image_path = take_screenshot()
    screen_context = summarize_screen_for_gpt(image_path)
    plan = ask_gpt(command, screen_context)
    print("ğŸ“¥ ×ª×•×›× ×™×ª:\n", plan)
    execute_plan(plan)

# ğŸ’¬ ×¤×§×•×“×” ×—×›××” ××”××¡×š â€“ ×¢× ×”×‘× ×ª ×˜×§×¡×˜×™×
def handle_command(command):
    try:
        command = command.strip()
        print(f"\nğŸ¯ ×¤×§×•×“×”: {command}")
        if any(k in command for k in ["×¤×ª×— ××ª×¨", "×ª×™×›× ×¡ ×œ", "×ª×ª×—×™×œ ×‘", "×ª×¤×ª×— ××ª"]):
            site = command.replace("×¤×ª×— ××ª×¨", "").replace("×ª×™×›× ×¡ ×œ", "").replace("×ª×ª×—×™×œ ×‘", "").replace("×ª×¤×ª×— ××ª", "").strip()
            url = clean_url(site)
            if url:
                web_browser_utils.open_website(url)
                wait_until_page_has_text()
                focus_browser_window()
            return

        image_path = take_screenshot()
        texts_with_positions = extract_texts_with_positions(image_path)
        context = "\n".join([f"{t['text']} @ ({t['x']},{t['y']})" for t in texts_with_positions])
        print("ğŸ–¼ï¸ ×˜×§×¡×˜×™× ×‘××¡×š:\n", context)

        if "×¢×¨×•×š ×¡×¨×˜×•×Ÿ" in command:
            prompt = get_video_editing_prompt(command, context)
        else:
            prompt = f"""
ğŸ§  ×‘×§×©×”: ×”×‘×Ÿ ××ª ×”×‘×§×©×” ×•×‘×¦×¢ ×œ×¤×™ ××” ×©×¨×•××™× ×‘××¡×š

×¤×§×•×“×”:
{command}

×˜×§×¡×˜×™× ×‘××¡×š:
{context}

×”×—×–×¨ ×¨×§ ×©×•×¨×•×ª ×¤×¢×•×œ×”:
- ×¤×ª×— ××ª×¨ <×›×ª×•×‘×ª>
- ×œ×—×¥ ×¢×œ <×˜×§×¡×˜>
- ×”×§×œ×“ ××ª <×©×“×”>
- ×¦×œ× ××¡×š
- ×§×¨× ××”××¡×š
- ×¢×¨×•×š ×¡×¨×˜×•×Ÿ
"""

        print("\nğŸ“¤ ×©×•×œ×— ×œÖ¾GPT:\n", prompt)
        plan = ask_gpt(prompt)
        print("\nğŸ“¥ ×ª×•×›× ×™×ª:\n", plan)
        execute_plan(plan)

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×›×œ×œ×™×ª: {e}")
