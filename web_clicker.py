# web_clicker.py â€“ ×œ×—×™×¦×” ×—×›××” ×¢×œ ×›×¤×ª×•×¨×™× ××ª×•×š HTML ×©×œ ××ª×¨

import requests
from bs4 import BeautifulSoup
import time
from fuzzywuzzy import fuzz

try:
    import pyautogui
    PYAUTOGUI_AVAILABLE = True
except ImportError:
    PYAUTOGUI_AVAILABLE = False

# ğŸ”‘ ××™×œ×•×ª ××¤×ª×— ×¨×œ×•×•× ×˜×™×•×ª ×œ×œ×—×™×¦×” (×¢×‘×¨×™×ª + ×× ×’×œ×™×ª)
CLICK_KEYWORDS = [
    "get started", "start", "create", "sign up", "register", "join", "open",
    "start now", "begin", "start for free", "try it", "try for free", "continue", "go",
    "×‘×—×¨", "×”×ª×—×œ", "×¦×•×¨", "×¦×•×¨ ×—×©×‘×•×Ÿ", "×”×™×¨×©×", "×”×ª×—×œ ×¢×›×©×™×•", "×”×ª×—×œ ×‘×—×™× ×",
    "× ×¡×”", "× ×¡×” ×‘×—×™× ×", "×”××©×š", "×§×“×™××”", "×œ×¤×ª×™×—×”", "×œ×™×¦×™×¨×”", "×”×¤×¢×œ",
    "×›× ×™×¡×”", "×›× ×™×¡×ª ××©×ª××©", "×”×¨×©××”", "×”×™×¨×©× ×¢×›×©×™×•", "×œ×”×ª×—×™×œ", "×›× ×™×¡×” ×œ×—×©×‘×•×Ÿ"
]

def extract_all_text_candidates(soup):
    """
    ğŸ” ×©×•×œ×£ ×˜×§×¡×˜×™× ×¤×•×˜× ×¦×™××œ×™×™× ×œ×œ×—×™×¦×” ××ª×•×š ×ª×’×™×•×ª ×‘××ª×¨.
    ×›×•×œ×œ aria-label, placeholder, alt, title, value ×•×¢×•×“.
    """
    tags = ["a", "button", "input", "label", "div", "span"]
    candidates = set()

    for el in soup.find_all(tags):
        texts = [
            el.get_text(strip=True),
            el.get("aria-label", ""),
            el.get("alt", ""),
            el.get("title", ""),
            el.get("placeholder", ""),
            el.get("value", "") if el.name == "input" else ""
        ]
        for t in texts:
            t = t.strip()
            if 2 < len(t) < 80 and t.lower() not in ["submit", "click here"]:
                candidates.add(t)

    return list(candidates)

def click_button_on_page(url, keywords=None, match_threshold=80):
    """
    ğŸ§  ×× ×¡×” ×œ××ª×¨ ×›×¤×ª×•×¨ ×œ×¤×™ ×˜×§×¡×˜ ×‘××ª×¨ ×•×œ×‘×¦×¢ ×¢×œ×™×• ×œ×—×™×¦×” ××•×˜×•××˜×™×ª ×‘×××¦×¢×•×ª Ctrl+F + Enter.
    """
    if keywords is None:
        keywords = CLICK_KEYWORDS

    print(f"ğŸŒ ×˜×•×¢×Ÿ ××ª ×”××ª×¨: {url}")
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status()
    except Exception as e:
        return f"âŒ ×©×’×™××” ×‘×˜×¢×™× ×ª ×”×“×£: {e}"

    soup = BeautifulSoup(response.text, "html.parser")
    candidates = extract_all_text_candidates(soup)
    print(f"ğŸ” × ××¦××• {len(candidates)} ×˜×§×¡×˜×™× ×¤×•×˜× ×¦×™××œ×™×™× ×œ×œ×—×™×¦×”")

    best_text, best_score, best_keyword = "", 0, ""

    for keyword in keywords:
        for text in candidates:
            score = fuzz.token_sort_ratio(keyword.lower(), text.lower())
            if score > best_score and score >= match_threshold:
                best_score = score
                best_text = text
                best_keyword = keyword

    if best_text:
        print(f"âœ… ×˜×§×¡×˜ ×ª×•××: '{best_text}' (×”×ª×××” ×œÖ¾'{best_keyword}' â€“ {best_score}%)")

        if PYAUTOGUI_AVAILABLE:
            try:
                pyautogui.hotkey("ctrl", "f")
                time.sleep(0.4)
                pyautogui.typewrite(best_text[:50])
                time.sleep(0.6)
                pyautogui.press("esc")   # ×œ×¡×’×•×¨ Ctrl+F
                time.sleep(0.3)
                pyautogui.press("enter") # × ×™×¡×™×•×Ÿ ×œ×—×™×¦×”
                return f"âœ… ×‘×•×¦×¢×” ×œ×—×™×¦×” ×¢×œ '{best_text}'"
            except Exception as e:
                return f"âŒ ×©×’×™××” ×‘Ö¾pyautogui: {e}"
        else:
            return f"ğŸ” × ××¦× ×˜×§×¡×˜ ×ª×•××: '{best_text}' (×œ×œ× ×‘×™×¦×•×¢ â€“ pyautogui ×œ× ××•×ª×§×Ÿ)"

    return "âŒ ×œ× × ××¦× ×›×¤×ª×•×¨ ××ª××™× ğŸ˜"
